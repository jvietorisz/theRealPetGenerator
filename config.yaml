# Train or analyze performance
train_mode: 0 # remote
eval_mode: 1 # non-remote
generate_mode: 0 # remote

# Dataset specs
nchannels: 3 # 1 or 3
img_size: 64 # = height = width
latent_size: 100

# Train specs
batch_size: 4 # True batch size is batch_size * n_GPU
num_epochs: 2400
update_every: 2 # Update discriminator every __ batches
print_every: 100 # Print stats every __ batches

# Data labels
real_labels: 1 # Can smooth here
fake_labels: 0 # Can smooth here

# Optimizer
lr: 0.0002
beta1: 0.5

# GPU setup
gpu_type: 'nvidia' # mac, nvidia
multiple_gpus: True

# Num samples to make
num_constant: 10 # Number of samples to save per epoch
num_generate: 40 # Number of samples to generate in generate_mode

# Filenames for saved stuff

# Save finished models
d_fname: 'd_model.pth' # Save D model here
g_fname: 'g_model.pth' # Save G model here


# Saved samples
generated_fname: 'generated_fname.npy' # Numpy array (num_generate, nchannels, img_size, img_size) to save final model generations
samples_fname: 'train_samples.npy' # Numpy array (epoch, num_constant, nchannels, img_size, img_size) to save samples epoch by epoch

# For plotting
losses_fname: 'train_losses.npy' # Numpy array (epoch, 2) - gen, disc
acc_fname: 'train_accuracies.npy' # Numpy array (epoch, 2) - real, fake
av_preds_fname: 'train_av_preds.npy' # Numpy array (epoch, 2) - real, fake
 
# Filenames for logging
log_fname: 'train_log' # Instead of print statement
